{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Does offline(known) and offline(unknown) equilavent?"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","from datetime import datetime\n","import coptpy as cp \n","from coptpy import COPT\n","\n","def offline_policy_linear(env_dict,T_type='unknown', runtime = False, Qcons = False):\n","    env = cp.Envr()\n","    model = env.createModel(\"offline_policy\")\n","    model.setParam('Logging', False)\n","\n","    B,bmax,fun = env_dict['B'],env_dict['bmax'],env_dict['f']\n","    T = env_dict['N'] if T_type == 'known' else env_dict['N_max']\n","    x = model.addMVar(T, lb=0, ub=bmax,vtype=COPT.CONTINUOUS, nameprefix=\"x\")\n","    f = np.array([fun[t]['params']['f1'] for t in range(T)])\n","    if T_type == 'known':\n","        def loss(x):\n","            return f@x\n","        model.addConstr(x@np.ones(T)<=B)\n","    elif T_type == 'unknown':\n","        def loss(x):\n","            return f@np.diag(env_dict['Qs'][:T])@x\n","        if Qcons:\n","            model.addConstr(x@np.array(env_dict['Qs'][:T])<=B)\n","        else:\n","            model.addConstr(x@np.ones(T)<=B)\n","    start_time = datetime.now()\n","    model.setObjective(loss(x), sense=COPT.MAXIMIZE)\n","    model.solve()\n","    if model.status == COPT.OPTIMAL:\n","        solution=[(x[t].X) for t in range(T)]\n","        fun = model.objval\n","    else:\n","        print(\"Optimization was stopped with status:\", model.status)\n","        solution=None\n","        fun=None\n","    if runtime:\n","        print('optimization time for N={T}:', datetime.now()-start_time)\n","    return solution, fun"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["from scipy.stats import rv_discrete\n","\n","args = {\n","        'N_type': 'normal',\n","        'N_min': 5,\n","        'N_max':200, # NOTE: when Q_exp, set large N_max(200)!\n","                    # NOTE: when Q_power, set large N_max(70)!\n","        'N_mean':10,\n","        'N_std':1,\n","        'B_type':'mean',\n","        'astype':'multiplicative',\n","        'as_scale':5,\n","        'as_stepsize':10,\n","        'max_scale':50,\n","        'rounds':3,\n","        'Q_beta':0.99,\n","        'Q_alpha':0.75,\n","        'f_shape':'linear',\n","        'f_coef':rv_discrete(values=([2,3], [0.5,0.5])),# x**0.9\n","    }"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["[0.0, 0.0, 1.0, 0.0]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["N_mean = 3\n","N_min, N_max = N_mean, N_mean \n","rv = rv_discrete(values=([N_mean],[1]))\n","Qs = np.array([1 - rv.cdf(t - 0.001) for t in range(1, N_max + 1)]+[0])\n","Qs\n","probs = [Qs[n]-Qs[n+1] for n in range(N_max)]\n","probs.append(Qs[-1])\n","probs"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[1.         1.         1.         0.95384276 0.70058933 0.29941067\n"," 0.04615724 0.        ]\n","[0.0, 0.0, 0.04615723572698305, 0.2532534356100451, 0.4011786573259435, 0.2532534356100453, 0.04615723572698305, 0.0]\n"]},{"data":{"text/plain":["1.0"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["from scipy.stats import truncnorm\n","from src.utils import rv_cont2dsct\n","N_mean = 5\n","N_std = 1\n","N_min, N_max = N_mean-2*N_std, N_mean+2*N_std #[3,7]\n","a, b = (N_min - N_mean) / N_std, (N_max - N_mean) / N_std\n","rv_continuous = truncnorm(a, b, loc=N_mean, scale=N_std) \n","rv = rv_cont2dsct(rv_continuous,N_min,N_max)\n","Qs = np.array([1 - rv.cdf(t - 0.001) for t in range(1, N_max + 1)]+[0])\n","print(Qs)\n","probs = [Qs[n]-Qs[n+1] for n in range(N_max)]\n","probs.append(Qs[-1])\n","print(probs)\n","sum(probs)"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[1.         0.88599203 0.68949151 0.5286105  0.39689227 0.2890505\n"," 0.20075713 0.12846863 0.06928381 0.02082738 0.        ]\n","[0.11400797317891087, 0.1965005138243826, 0.16088101366364715, 0.131718233472787, 0.10784176848527638, 0.08829337232521173, 0.07228849921561509, 0.05918481740167769, 0.04845643012205836, 0.02082737831043313, 0.0]\n"]},{"data":{"text/plain":["1.0"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["from scipy.stats import truncnorm, truncexpon\n","from src.utils import rv_cont2dsct\n","N_mean = 5\n","N_min = 1\n","N_max = 2*N_mean \n","b = (N_max - N_min) / N_mean\n","rv_continuous = truncexpon(b=b, loc=N_min, scale=N_mean)\n","rv = rv_cont2dsct(rv_continuous,N_min,N_max)\n","Qs = np.array([1 - rv.cdf(t - 0.001) for t in range(1, N_max + 1)]+[0])\n","print(Qs)\n","probs = [Qs[n]-Qs[n+1] for n in range(N_max)]\n","probs.append(Qs[-1])\n","print(probs)\n","sum(probs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from src.Env import Envr\n","env = Envr(args)\n","env_dict = env.draw_instance()\n","Qs = env_dict['Qs']\n","probs = [Qs[n]-Qs[n+1] for n in range(env_dict['N_max'])]\n","probs.append(Qs[-1])\n","known_reward = 0\n","for T in range(env.N_min,env.N_max+1):\n","    env_dict['N'] = T\n","    _,fun_known = offline_policy_linear(env_dict,'known',False)\n","    known_reward += probs[T-1]*fun_known\n","_,fun_unknown = offline_policy_linear(env_dict,'unknown',False,True)\n","print(known_reward,fun_unknown)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def offline_policy_sqrt(env_dict,T_type='unknown', runtime = False, Qcons = False):\n","    env = cp.Envr()\n","    model = env.createModel(\"offline_policy\")\n","    model.setParam('Logging', False)\n","\n","    B,bmax,fun = env_dict['B'],env_dict['bmax'],env_dict['f']\n","    T = env_dict['N'] if T_type == 'known' else env_dict['N_max']\n","    x = model.addMVar(T, lb=0, ub=np.sqrt(bmax),vtype=COPT.CONTINUOUS, nameprefix=\"x\")\n","    f = np.array([fun[t]['params']['f1'] for t in range(T)])\n","    if T_type == 'known':\n","        def loss(x):\n","            return f@x\n","        model.addQConstr(x@x<=B)\n","    elif T_type == 'unknown':\n","        def loss(x):\n","            return f@np.diag(env_dict['Qs'][:T])@x\n","        if Qcons:\n","            model.addQConstr(x@np.diag(env_dict['Qs'][:T])@x<=B)\n","        else:\n","            model.addQConstr(x@x<=B)\n","    start_time = datetime.now()\n","    \n","    model.setObjective(loss(x), sense=COPT.MAXIMIZE)\n","    model.solve()\n","    if model.status == COPT.OPTIMAL:\n","        solution=[(x[t].X)**2 for t in range(T)]\n","        fun = model.objval\n","    else:\n","        print(\"Optimization was stopped with status:\", model.status)\n","        solution=None\n","        fun=None\n","    if runtime:\n","        print('optimization time for N={T}:', datetime.now()-start_time)\n","    return solution, fun"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from src.Env import Envr\n","args['f_shape'] = 'sqrt'\n","env = Envr(args)\n","env_dict = env.draw_instance()\n","Qs = env_dict['Qs']\n","probs = [Qs[n]-Qs[n+1] for n in range(env_dict['N_max'])]\n","probs.append(Qs[-1])\n","known_reward = 0\n","for T in range(env.N_min,env.N_max+1):\n","    env_dict['N'] = T\n","    _,fun_known = offline_policy_sqrt(env_dict,'known',False)\n","    known_reward += probs[T-1]*fun_known\n","_,fun_unknown_Q = offline_policy_sqrt(env_dict,'unknown',False,True)\n","_,fun_unknown = offline_policy_sqrt(env_dict,'unknown',False,False)\n","print(known_reward,fun_unknown_Q,fun_unknown)"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["def wrapper(args,f_shape,random_coef,N_type):\n","    args['N_type'] = N_type \n","    args['f_shape'] = f_shape\n","    if random_coef:\n","        args['f_coef']=rv_discrete(values=([2,3], [0.5,0.5]))\n","    else:\n","        args['f_coef']=rv_discrete(values=([2,2], [0.5,0.5]))\n","    env = Envr(args)\n","    env_dict = env.draw_instance()\n","    Qs = env_dict['Qs']\n","    probs = [Qs[n]-Qs[n+1] for n in range(env_dict['N_max'])]\n","    probs.append(Qs[-1])\n","    known_reward = 0\n","    for T in range(env.N_min,env.N_max+1):\n","        env_dict['N'] = T\n","        _,fun_known = offline_policy_linear(env_dict,'known',False)\n","        known_reward += probs[T-1]*fun_known\n","    _,fun_unknown_Q = offline_policy_linear(env_dict,'unknown',False,True)\n","    _,fun_unknown = offline_policy_linear(env_dict,'unknown',False,False)\n","    result = [f\"{f_shape}_RandomCoef_{random_coef}_{N_type}: exact {known_reward} approx_Q {fun_unknown_Q} approx {fun_unknown}\"]\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["all_result = []\n","result = wrapper(args,'linear',True,'normal')\n","all_result.append(result)\n","\n","result = wrapper(args,'linear',False,'normal')\n","all_result.append(result)\n","\n","result = wrapper(args,'sqrt',True,'normal')\n","all_result.append(result)\n","\n","result = wrapper(args,'sqrt',False,'normal')\n","all_result.append(result)\n"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['linear_RandomCoef_True_normal: exact 167.02831319698186 approx_Q 167.0283131969817 approx 161.90412135301594']\n","['linear_RandomCoef_False_normal: exact 120.0 approx_Q 120.0 approx 120.0']\n","['sqrt_RandomCoef_True_normal: exact 162.04957890126454 approx_Q 162.04957890126448 approx 159.2947146967115']\n","['sqrt_RandomCoef_False_normal: exact 120.0 approx_Q 120.0 approx 120.0']\n"]}],"source":["for result in all_result:\n","    print(result)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["all_result = []\n","result = wrapper(args,'linear',True,'exponential')\n","all_result.append(result)\n","\n","result = wrapper(args,'linear',False,'exponential')\n","all_result.append(result)\n","\n","result = wrapper(args,'sqrt',True,'exponential')\n","all_result.append(result)\n","\n","result = wrapper(args,'sqrt',False,'exponential')\n","all_result.append(result)"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['linear_RandomCoef_True_exponential: exact 90.38967692322203 approx_Q 104.14306039271825 approx 87.1304439713688']\n","['linear_RandomCoef_False_exponential: exact 70.26807430484193 approx_Q 84.02145777433813 approx 70.26807430484193']\n","['sqrt_RandomCoef_True_exponential: exact 87.73898576320818 approx_Q 101.49236923270436 approx 83.86335925448854']\n","['sqrt_RandomCoef_False_exponential: exact 70.26807430484193 approx_Q 84.02145777433813 approx 70.26807430484193']\n"]}],"source":["for result in all_result:\n","    print(result)"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"data":{"text/plain":["48"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["env.N_min"]},{"cell_type":"markdown","metadata":{},"source":["## 结论\n","b is always linear\n","\n","f is linear, 与约束不加Q等价 [9.974094096084459 9.974094096084459]\n","\n","f is sqrt, 始终不等价(加 Q [9.948586323679674 10.000000049839336],\n","                        不加Q [9.948586323679674 9.482202012847173])"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":2}
